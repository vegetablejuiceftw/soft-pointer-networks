{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/fred/projects/soft-pointer-networks/clean-start-ce.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[1;32m      5\u001B[0m warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 7\u001B[0m module \u001B[38;5;241m=\u001B[39m \u001B[43mThing\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_from_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mclean-start-ce.ckpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m trainer \u001B[38;5;241m=\u001B[39m pl\u001B[38;5;241m.\u001B[39mTrainer(accelerator\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgpu\u001B[39m\u001B[38;5;124m'\u001B[39m, devices\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m1\u001B[39m])\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/soft-pointer-network-OI7XEqck-py3.8/lib/python3.8/site-packages/pytorch_lightning/core/saving.py:134\u001B[0m, in \u001B[0;36mModelIO.load_from_checkpoint\u001B[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001B[0m\n\u001B[1;32m    132\u001B[0m         checkpoint \u001B[38;5;241m=\u001B[39m pl_load(checkpoint_path, map_location\u001B[38;5;241m=\u001B[39mmap_location)\n\u001B[1;32m    133\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 134\u001B[0m         checkpoint \u001B[38;5;241m=\u001B[39m \u001B[43mpl_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloc\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m hparams_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    137\u001B[0m     extension \u001B[38;5;241m=\u001B[39m hparams_file\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/soft-pointer-network-OI7XEqck-py3.8/lib/python3.8/site-packages/pytorch_lightning/utilities/cloud_io.py:37\u001B[0m, in \u001B[0;36mload\u001B[0;34m(path_or_url, map_location)\u001B[0m\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mhub\u001B[38;5;241m.\u001B[39mload_state_dict_from_url(\u001B[38;5;28mstr\u001B[39m(path_or_url), map_location\u001B[38;5;241m=\u001B[39mmap_location)\n\u001B[1;32m     36\u001B[0m fs \u001B[38;5;241m=\u001B[39m get_filesystem(path_or_url)\n\u001B[0;32m---> 37\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mfs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_or_url\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mload(f, map_location\u001B[38;5;241m=\u001B[39mmap_location)\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/soft-pointer-network-OI7XEqck-py3.8/lib/python3.8/site-packages/fsspec/spec.py:1009\u001B[0m, in \u001B[0;36mAbstractFileSystem.open\u001B[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001B[0m\n\u001B[1;32m   1007\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1008\u001B[0m     ac \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mautocommit\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_intrans)\n\u001B[0;32m-> 1009\u001B[0m     f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1010\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1011\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1012\u001B[0m \u001B[43m        \u001B[49m\u001B[43mblock_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mblock_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1013\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautocommit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mac\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1014\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1015\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1016\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1017\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m compression \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1018\u001B[0m         \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfsspec\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompression\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compr\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/soft-pointer-network-OI7XEqck-py3.8/lib/python3.8/site-packages/fsspec/implementations/local.py:155\u001B[0m, in \u001B[0;36mLocalFileSystem._open\u001B[0;34m(self, path, mode, block_size, **kwargs)\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_mkdir \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m    154\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmakedirs(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parent(path), exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m--> 155\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mLocalFileOpener\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/soft-pointer-network-OI7XEqck-py3.8/lib/python3.8/site-packages/fsspec/implementations/local.py:250\u001B[0m, in \u001B[0;36mLocalFileOpener.__init__\u001B[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001B[0m\n\u001B[1;32m    248\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompression \u001B[38;5;241m=\u001B[39m get_compression(path, compression)\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocksize \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mDEFAULT_BUFFER_SIZE\n\u001B[0;32m--> 250\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/soft-pointer-network-OI7XEqck-py3.8/lib/python3.8/site-packages/fsspec/implementations/local.py:255\u001B[0m, in \u001B[0;36mLocalFileOpener._open\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    253\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf\u001B[38;5;241m.\u001B[39mclosed:\n\u001B[1;32m    254\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mautocommit \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m--> 255\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompression:\n\u001B[1;32m    257\u001B[0m             compress \u001B[38;5;241m=\u001B[39m compr[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompression]\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/fred/projects/soft-pointer-networks/clean-start-ce.ckpt'"
     ]
    }
   ],
   "source": [
    "from load import wds_load\n",
    "from streamlined_example import MyCustomDataset, Thing, fix_borders, report_borders, report_duration\n",
    "import pytorch_lightning as pl\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "module = Thing.load_from_checkpoint(\"clean-start-ce.ckpt\", strict=False)\n",
    "trainer = pl.Trainer(accelerator='gpu', devices=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "limit = 8\n",
    "split = \"train\"\n",
    "file_path = f\"{split}_data_0.03wl_0.015ws.tar.xz\"\n",
    "files = wds_load(file_path, limit)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = MyCustomDataset(files)\n",
    "generated = sum(trainer.predict(module.with_weights, dataloaders=dataset.batch(32, shuffle=False)), start=[])\n",
    "generated, items = generated[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generated[0].sum(axis=1, keepdims=True).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def show_tensor(aTensor, index=1, figsize=(32, 32), hide_x=False, labels=None, cmap=None, fig=True):\n",
    "    if len(aTensor.shape) > 2:\n",
    "        aTensor = aTensor[index]\n",
    "\n",
    "    if hasattr(aTensor, 'detach'): aTensor = aTensor.detach()\n",
    "    if hasattr(aTensor, 'cpu'): aTensor = aTensor.cpu()\n",
    "    if hasattr(aTensor, 'numpy'): aTensor = aTensor.numpy()\n",
    "\n",
    "    fig and plt.figure(figsize=figsize)\n",
    "    plt.title(str(aTensor.shape))\n",
    "    plt.imshow(aTensor, cmap='winter')\n",
    "    plt.clim(0, 1)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calculate(att: torch.FloatTensor, target: torch.FloatTensor):\n",
    "    arr = att[:target.shape[0]].unsqueeze(0)\n",
    "    delta = target - target.clone().to(torch.long)\n",
    "    target = target.unsqueeze(1).unsqueeze(0).to(torch.long)\n",
    "    # target = torch.dstack([target - 1, target, target + 1])\n",
    "    target = torch.dstack([target - 2, target - 1, target, target + 1, target + 2, target + 3])\n",
    "    print(\"\\n\", arr.shape, target.shape)\n",
    "\n",
    "    result = torch.take_along_dim(arr, target, 2)\n",
    "    gradient = torch.FloatTensor([1, 2, 3, 4, 5, 6])\n",
    "    diff = (result * gradient).sum(axis=-1) - (delta + 3)\n",
    "    print(diff.mean())\n",
    "    result = result.sum(axis=-1)\n",
    "\n",
    "    calc = result.round(decimals=1)\n",
    "    print(calc.mean(), calc.shape)\n",
    "    display(pd.DataFrame(calc.squeeze(0)).T)\n",
    "    return result\n",
    "\n",
    "index = -1\n",
    "item = items[index]\n",
    "gen = torch.FloatTensor(generated[index].copy()).unsqueeze(0)\n",
    "show_tensor(gen[0])\n",
    "target = torch.FloatTensor(item.target_timestamps[:-1])\n",
    "calc = calculate(gen[0], target).round(decimals=1)\n",
    "\n",
    "gen /= 5\n",
    "gen[0, :, item.features_spectogram.shape[0]:] = 0.1\n",
    "\n",
    "for i, b in enumerate(item.target_timestamps):\n",
    "    gen[0, i, int(b)] = 1\n",
    "\n",
    "calc = calculate(gen[0], target).round(decimals=1)\n",
    "show_tensor(gen[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.log(torch.FloatTensor([0, 0.5, 1.0, 1.5]).clip(0.0001, 0.9999)).round(decimals=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f = torch.nn.Softmax(dim=0)\n",
    "arr = torch.FloatTensor([(i % 4) * 2  for i in range(10)])\n",
    "\n",
    "for i in range(30):\n",
    "    print()\n",
    "    print(arr.round(decimals=1))\n",
    "    print(f(arr).round(decimals=2))\n",
    "    arr.requires_grad = True\n",
    "    arr.retain_grad()\n",
    "\n",
    "    loss = f(arr)[2]\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    arr.grad.round(decimals=2)\n",
    "\n",
    "    arr = arr.grad + arr.detach()\n",
    "    arr = arr.detach().clone()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "criteria = torch.nn.MSELoss()\n",
    "f = torch.nn.Softmax(dim=0)\n",
    "cross = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "count = 15\n",
    "index = 5\n",
    "gradient = torch.FloatTensor(range(count))\n",
    "\n",
    "arr = torch.FloatTensor([0 + 0.1 * i for i in range(count)])\n",
    "# arr[-1] = 0\n",
    "# arr[1] = -90\n",
    "arr[index] = 2\n",
    "\n",
    "arr.requires_grad = True\n",
    "arr.retain_grad()\n",
    "\n",
    "# pred = (f(arr) * gradient).sum().unsqueeze(0)\n",
    "# pred.retain_grad()\n",
    "#\n",
    "# target = torch.FloatTensor([index])\n",
    "# print(pred, pred.shape, target.shape)\n",
    "# loss = criteria(pred, target)\n",
    "\n",
    "# print(arr.shape, torch.LongTensor([index]).shape)\n",
    "loss = cross(arr.unsqueeze(0), torch.LongTensor([index]))\n",
    "loss.backward()\n",
    "print(loss)\n",
    "\n",
    "torch.stack([arr, f(arr), gradient, f(arr) * gradient, arr.grad.abs()]).detach().numpy().round(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cross(arr.unsqueeze(0),torch.LongTensor([24]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mask_transcription = torch.load('mask_transcription.pt')#  * 1.0\n",
    "mask_audio = torch.load('mask_audio.pt')# * 1.0\n",
    "w = torch.load('w.pt')\n",
    "# w += torch.rand_like(w) * 0.1\n",
    "\n",
    "w = w * mask_audio.unsqueeze(1) * mask_transcription.unsqueeze(2)\n",
    "print(mask_audio.shape)\n",
    "w = torch.sub(w, ((~mask_audio) * 9999999).unsqueeze(1))\n",
    "w = w[-1:, :-1, :]\n",
    "\n",
    "target = torch.LongTensor([  0,   9,  17,  25,  33,  42,  51,  59,  67,  75,  83,  92, 101, 108,\n",
    "        117, 125, 134, 142, 151, 159, 167, 176, 183, 192, 201, 209, 218, 226,\n",
    "        234, 243, 251, 259, 267, 276, 284, 292, 300, 309, 318, 325, 335, 343,\n",
    "        351, 359, 366, 377, 384, 392, 402, 409, 418, 425, 434, 443, 452, 459,\n",
    "        467, 477, 484, 492])[:-1].unsqueeze(0)\n",
    "\n",
    "mask_transcription = mask_transcription[-1:, :-1]\n",
    "print(target.shape, mask_transcription.shape)\n",
    "target = torch.mul(target, mask_transcription) + (~mask_transcription) * -100\n",
    "\n",
    "print(w.shape, target.shape)\n",
    "# target[0, 30:] = -100\n",
    "cross = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
    "cross(w.transpose(1, 2), (target + 0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(target)\n",
    "ww = w[0].clone() * 1\n",
    "# ww[:, 275:] = -999999999\n",
    "\n",
    "# for i, t in enumerate(target[0]):\n",
    "#     ww[i, t] = 1\n",
    "\n",
    "print(cross(ww.unsqueeze(0).transpose(1, 2), (target + 0)))\n",
    "\n",
    "show_tensor(ww)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def show_tensor(aTensor, index=1, figsize=(64, 64), hide_x=False, labels=None, cmap=None, fig=True):\n",
    "    # print(aTensor.shape, aTensor.sum())\n",
    "    if len(aTensor.shape) > 2:\n",
    "        aTensor = aTensor[index]\n",
    "\n",
    "    if hasattr(aTensor, 'detach'): aTensor = aTensor.detach()\n",
    "    if hasattr(aTensor, 'cpu'): aTensor = aTensor.cpu()\n",
    "    if hasattr(aTensor, 'numpy'): aTensor = aTensor.numpy()\n",
    "\n",
    "    fig and plt.figure(figsize=figsize)\n",
    "    plt.title(str(aTensor.shape))\n",
    "    plt.imshow(aTensor, cmap='Greys')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "mask_transcription = torch.load('mask_transcription.pt')  * 1.0\n",
    "mask_audio = torch.load('mask_audio.pt') * 1.0\n",
    "w = torch.load('w.pt')\n",
    "r = torch.rand_like(w) * 0.1\n",
    "w = w * mask_audio.unsqueeze(1) * mask_transcription.unsqueeze(2)\n",
    "# w += r\n",
    "print(w.shape)\n",
    "show_tensor(w)\n",
    "show_tensor(mask_transcription + torch.rand_like(mask_transcription) * 0.1)\n",
    "show_tensor(mask_audio + torch.rand_like(mask_audio) * 0.1)\n",
    "# print(mask_transcription)\n",
    "# print(mask_audio)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w_cum = torch.cumsum(w, dim=2) * mask_audio.unsqueeze(1)\n",
    "show_tensor(w_cum)\n",
    "show_tensor(torch.roll(w_cum, -1, 1) * mask_transcription.unsqueeze(2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w_changed = w.clone()\n",
    "w_changed[1, 16, 200: 220] = 1\n",
    "w_changed[1, 16, 50: 60] = 1\n",
    "\n",
    "mask = mask_transcription.clone()\n",
    "mask[:, :-1] *= mask[:, 1:]\n",
    "mask[:, -1] = False\n",
    "\n",
    "w_cum_roll = 1 - torch.roll(w_cum, -1, 1) * mask.unsqueeze(2)\n",
    "w_new = w_changed * w_cum_roll\n",
    "\n",
    "w_new = torch.div(w_new, w_new.sum(dim=2).unsqueeze(2))\n",
    "w_new = torch.nan_to_num(w_new)\n",
    "\n",
    "for i in range(2):\n",
    "    show_tensor(w_changed, index=i)\n",
    "    show_tensor(w_cum_roll, index=i)\n",
    "    show_tensor(w_new, index=i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w_new.sum(dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}